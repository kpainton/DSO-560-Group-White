{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpainton/opt/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.layers import Dense, Flatten, Embedding, Masking, Bidirectional\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chubby-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Spring 2021 Class Notes\n",
    "from typing import List\n",
    "\n",
    "# Encodes documents into integers\n",
    "def integer_encode_documents(docs: List[str], tokenizer: Tokenizer)-> List[List[int]]:\n",
    "    documents = []\n",
    "    for d in docs:\n",
    "        doc_integers = []\n",
    "        for i in text_to_word_sequence(d):\n",
    "            doc_integers.append(tokenizer.word_index[i])\n",
    "        documents.append(doc_integers)\n",
    "    return documents\n",
    "\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "geological-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines the maximum token length for a group of documents\n",
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepting-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Professors Function: Concates the keys together\n",
    "def concat_keys(x):\n",
    "    first, second = x[0], x[1]\n",
    "    if first <= second:\n",
    "        return f\"{first}{second}\"\n",
    "    else:\n",
    "        return f\"{second}{first}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civic-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes characters\n",
    "def replace(replacements):\n",
    "    for replace in replacements: \n",
    "        genres['overview'] = genres['overview'].str.replace(replace, '', case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "environmental-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpainton/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "reviews = pd.read_csv('movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collected-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses JSON to find the genres for the movie\n",
    "regex = \"\\'name\\': \\'([A-z]{1,})\"\n",
    "reviews['genres_group'] = reviews['genres'].str.findall(regex)\n",
    "\n",
    "# Parses JSON to find the production companies for a movie\n",
    "regex = \"\\'name\\': \\'([A-z]{1,})\"\n",
    "reviews['production_companies'] = reviews['production_companies'].str.findall(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "parental-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exlodes genres column to have one title, genre and overview per line\n",
    "# Note a movie can have multiple genres, in this dataset each observation for a movie represents \n",
    "reviews = reviews.explode('genres_group').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "referenced-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups genres into 7 different distinct categories\n",
    "reviews['genres_group'] = np.where(reviews['genres_group'] == 'Drama', 'Drama',\n",
    "                          np.where(reviews['genres_group'] == 'Comedy', 'Comedy', \n",
    "                          np.where(reviews['genres_group'].isin(['Thriller', 'Crime', 'Horror', 'Mystery']), 'Thriller/Horror',\n",
    "                          np.where(reviews['genres_group'].isin(['Action', 'Adventure', 'Science', 'Fantasy']), 'Action/Adventure',\n",
    "                          np.where(reviews['genres_group'].isin(['Animation', 'Family']), 'Animation/Family', \n",
    "                          np.where(reviews['genres_group'].isin(['History', 'War', 'Western']), 'History/War/Western', \n",
    "                          np.where(reviews['genres_group'] == 'Documentary', 'Documentary', 'Drop')))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "representative-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops genres that are too obsecure for the prediction purposes of this excercise\n",
    "reviews = reviews.loc[reviews['genres_group'] != 'Drop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "static-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = reviews[['original_title', 'overview', 'genres_group', 'production_companies', 'runtime', 'budget', 'revenue']]\n",
    "genres = genres.drop_duplicates(subset = ['original_title', 'genres_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "statewide-naples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama                  19515\n",
       "Comedy                 12958\n",
       "Thriller/Horror        12526\n",
       "Action/Adventure       10844\n",
       "Documentary             3929\n",
       "Animation/Family        3737\n",
       "History/War/Western     3290\n",
       "Name: genres_group, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of each genre\n",
    "genres['genres_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interpreted-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets all words in review to lowercase\n",
    "genres['overview'] = genres['overview'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "correct-wrist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searches for any malformed text that needs to be replaced\n",
    "genres['overview'].str.extract(r'(&#[0-9]+)')[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dress-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes any unneeded punctuation\n",
    "replace(['/><br', '<br', \"\\\"\", \"\\'\", \"/\", '=',\n",
    "         '<', '>', ',', '_', '\\n', '\\.', '-', '\\n', '\\(', '\\)', ':'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fleet-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops any missing data\n",
    "genres = genres.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "physical-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_duplicates = 'abcdefghijklmnopqrstuvwxyz!?'\n",
    "\n",
    "# Loops through the alphabet and replaces charaters that appear 3+ times in a row with one occurence\n",
    "for i in potential_duplicates: \n",
    "    if i == '?':\n",
    "        i = '\\?'\n",
    "    genres['overview'] = genres.overview.apply(lambda x: re.sub(i + i + i + '+', i, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "superb-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Spacy model to include POS tagging and lemmatization in pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "random-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs lemmatization on all genre summaries\n",
    "genres['overview'] = genres['overview'].apply(lambda x: ' '.join([token.lemma_ for token in nlp(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stylish-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets list of stop words\n",
    "# other stop words were selected based on word frequecnies\n",
    "stop_words = list(stopwords.words('english')) + ['also', 'well', 'much', 'get', 'take', 'make', 'try',\n",
    "                                                 'live', 'come', 'must', 'turn', 'film', 'movie', 'story',\n",
    "                                                 'back', 'way', 'set', 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fixed-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes stop words from data\n",
    "genres['overview'] = genres['overview'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "individual-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes any overviews that are missing genres\n",
    "genres = genres.loc[genres['overview'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-upgrade",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "invalid-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encodes categorical fields into a numerical array\n",
    "baseline_labels = to_categorical(encoder.fit_transform(genres['genres_group']))\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(genres['overview'], baseline_labels, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "finite-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collects document embeddings in train and test splits\n",
    "embeddings_train = np.concatenate(X_train_base.reset_index()['overview'].apply(lambda x: nlp(x).vector)).reshape(len(X_train_base), 96)\n",
    "embeddings_test = np.concatenate(X_test_base.reset_index()['overview'].apply(lambda x: nlp(x).vector)).reshape(len(X_test_base), 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "surrounded-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts array into a single value for genre label (between 0 and 6)\n",
    "y_train_base_num = [i.tolist().index(1) for i in y_train_base]\n",
    "y_test_base_num = [i.tolist().index(1) for i in y_test_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "tight-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpainton/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Fits and trains a basic LR model\n",
    "lr_w2v = LogisticRegression(random_state = 42)\n",
    "lr_w2v.fit(embeddings_train, y_train_base_num)\n",
    "\n",
    "# Gathers predictions based on Logisitc Regression model \n",
    "predictions_w2v = lr_w2v.predict(embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stuffed-first",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.17474451077608\n",
      "\n",
      "0.6412836093508879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 158,    3,  150,   28, 1123,    4,  169],\n",
       "       [  60,    0,  100,   10,  380,    1,   35],\n",
       "       [  97,    1,  335,   38, 1255,    0,  130],\n",
       "       [  24,    0,   44,   82,  412,    1,   16],\n",
       "       [ 117,    0,  280,   51, 2258,    4,  195],\n",
       "       [  38,    1,   33,   10,  361,    2,   27],\n",
       "       [ 123,    2,  169,   19, 1287,    4,  246]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints evaluation metrics\n",
    "print(np.mean(predictions_w2v == y_test_base_num) * 100)\n",
    "print()\n",
    "print(roc_auc_score(y_test_base_num, lr_w2v.predict_proba(embeddings_test), multi_class = 'ovo'))\n",
    "\n",
    "confusion_matrix(y_test_base_num, predictions_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "focal-doubt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.10      0.14      1635\n",
      "           1       0.00      0.00      0.00       586\n",
      "           2       0.30      0.18      0.23      1856\n",
      "           3       0.34      0.14      0.20       579\n",
      "           4       0.32      0.78      0.45      2905\n",
      "           5       0.12      0.00      0.01       472\n",
      "           6       0.30      0.13      0.18      1850\n",
      "\n",
      "    accuracy                           0.31      9883\n",
      "   macro avg       0.24      0.19      0.17      9883\n",
      "weighted avg       0.28      0.31      0.25      9883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_base_num, predictions_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-pitch",
   "metadata": {},
   "source": [
    "### Primary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "boring-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits tokenizer on text\n",
    "tokenizer = Tokenizer(num_words = 10000, oov_token = 'UNKNOWN_TOKEN')\n",
    "tokenizer.fit_on_texts(genres['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bibliographic-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates custom word embeddings based on the overview text\n",
    "docs = [word_tokenize(single) for single in genres['overview']]\n",
    "model = Word2Vec(docs, vector_size=300, window=10, min_count=1, workers=4)\n",
    "model.wv.save_word2vec_format('genre_overview.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faced-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer encodes and pads text\n",
    "docs = integer_encode_documents(genres['overview'], tokenizer)\n",
    "max_length = get_max_token_length_per_doc(genres['overview'])\n",
    "padded_docs = pad_sequences(docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "infectious-mandate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 73150 word vectors.\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# Loads word embeddings\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('genre_overview.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "embeddings_index = load_glove_vectors()\n",
    "\n",
    "# Creates embedding matrix based on the vocab size\n",
    "embedding_matrix_bbc = zeros((VOCAB_SIZE, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i == 10000:\n",
    "        break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix_bbc[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "black-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encodes categorical variables \n",
    "labels = to_categorical(encoder.fit_transform(genres['genres_group']))\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "raising-sweet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres_group\n",
       "Action/Adventure       0\n",
       "Animation/Family       1\n",
       "Comedy                 2\n",
       "Documentary            3\n",
       "Drama                  4\n",
       "History/War/Western    5\n",
       "Thriller/Horror        6\n",
       "Name: group_num, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows which genres correspond to which numerical label\n",
    "nums = [i.tolist().index(1) for i in labels]\n",
    "genres_copy = genres.copy()\n",
    "genres_copy['group_num'] = nums\n",
    "genres_copy.groupby('genres_group')['group_num'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-technique",
   "metadata": {},
   "source": [
    "### LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "actual-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "weird-poland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 146, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 146, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 3,043,271\n",
      "Trainable params: 43,271\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Complies a LSTM model, trying to predict 7 genre classes from text\n",
    "final_model = Sequential()\n",
    "final_model.add(Embedding(VOCAB_SIZE, 300, weights = [embedding_matrix_bbc], input_length = max_length, trainable = False))\n",
    "final_model.add(Masking(mask_value = 0.0))\n",
    "final_model.add(LSTM(units=32, input_shape = (1, max_length)))\n",
    "final_model.add(Dense(16))\n",
    "final_model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "final_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "twenty-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1853/1853 [==============================] - 97s 52ms/step - loss: 1.4469 - accuracy: 0.4159\n",
      "Epoch 2/5\n",
      "1853/1853 [==============================] - 96s 52ms/step - loss: 1.3743 - accuracy: 0.4429\n",
      "Epoch 3/5\n",
      "1853/1853 [==============================] - 94s 51ms/step - loss: 1.3555 - accuracy: 0.4482\n",
      "Epoch 4/5\n",
      "1853/1853 [==============================] - 94s 51ms/step - loss: 1.3450 - accuracy: 0.4516\n",
      "Epoch 5/5\n",
      "1853/1853 [==============================] - 94s 51ms/step - loss: 1.3335 - accuracy: 0.4550\n",
      "Accuracy: 46.346235\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "final_model.fit(X_train, y_train, epochs=5, verbose=1)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = final_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "civilian-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores model predictions as genre label (between 0 - 6)\n",
    "predictions = np.argmax(final_model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "identified-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_num = [i.tolist().index(1) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "rotary-tiger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  44.9\n",
      "ROC_AUC:  0.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 373,   23,  130,   24,  197,   31,  267],\n",
       "       [ 113,   42,   70,   13,   74,    2,   38],\n",
       "       [ 114,   33,  479,   18,  439,    9,  154],\n",
       "       [  14,    2,   33,  244,   73,    1,   15],\n",
       "       [ 133,   16,  278,   48, 1134,   24,  356],\n",
       "       [  38,    2,   23,   25,  189,   35,   27],\n",
       "       [ 186,    4,   88,   22,  281,    2,  653]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints evaluation metrics\n",
    "print('Accuracy: ', round(np.mean(predictions == y_test_num) * 100, 1))\n",
    "\n",
    "print('ROC_AUC: ', round(roc_auc_score(y_test_num, final_model.predict(X_test), multi_class = 'ovo'), 3))\n",
    "\n",
    "confusion_matrix(y_test_num, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "limited-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37      1045\n",
      "           1       0.34      0.12      0.18       352\n",
      "           2       0.44      0.38      0.41      1246\n",
      "           3       0.62      0.64      0.63       382\n",
      "           4       0.48      0.57      0.52      1989\n",
      "           5       0.34      0.10      0.16       339\n",
      "           6       0.43      0.53      0.48      1236\n",
      "\n",
      "    accuracy                           0.45      6589\n",
      "   macro avg       0.43      0.39      0.39      6589\n",
      "weighted avg       0.44      0.45      0.44      6589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_num, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-jordan",
   "metadata": {},
   "source": [
    "### Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "opponent-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 146, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 146, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "seq_self_attention (SeqSelfA (None, 146, 600)          38465     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                81024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 4,562,120\n",
      "Trainable params: 4,562,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Complies a Bi-directional LSTM model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=VOCAB_SIZE, output_dim=300, mask_zero=True, input_length = max_length))\n",
    "model.add(Bidirectional(LSTM(units=300,return_sequences=True, input_shape = (1, max_length))))\n",
    "model.add(SeqSelfAttention(attention_activation='softmax'))\n",
    "model.add(LSTM(units=32, input_shape = (1, max_length)))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "operating-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1853/1853 [==============================] - 1129s 609ms/step - loss: 1.6248 - accuracy: 0.3463\n",
      "Epoch 2/5\n",
      "1853/1853 [==============================] - 1165s 629ms/step - loss: 1.3511 - accuracy: 0.4457\n",
      "Epoch 3/5\n",
      "1853/1853 [==============================] - 1082s 584ms/step - loss: 1.2392 - accuracy: 0.4849\n",
      "Epoch 4/5\n",
      "1853/1853 [==============================] - 1096s 591ms/step - loss: 1.1726 - accuracy: 0.4991\n",
      "Epoch 5/5\n",
      "1853/1853 [==============================] - 1088s 587ms/step - loss: 1.1135 - accuracy: 0.5138\n",
      "Accuracy: 55.298084\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=5, verbose=1)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "advisory-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_num = [i.tolist().index(1) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "insured-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  41.235\n",
      "ROC_AUC:  0.795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[297,  43, 143,  24, 201,  30, 307],\n",
       "       [111,  47,  87,  17,  68,   0,  22],\n",
       "       [116,  48, 491,  36, 397,   9, 149],\n",
       "       [  6,   7,  29, 267,  52,   1,  20],\n",
       "       [154,  19, 349,  76, 984,  30, 377],\n",
       "       [ 29,   0,  25,  28, 188,  40,  29],\n",
       "       [205,   1, 103,  28, 298,  10, 591]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints evaluation metrics\n",
    "print('Accuracy: ', round(np.mean(predictions == y_test_num) * 100, 3))\n",
    "\n",
    "print('ROC_AUC: ', round(roc_auc_score(y_test_num, model.predict(X_test), multi_class = 'ovo'), 3))\n",
    "\n",
    "confusion_matrix(y_test_num, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "interstate-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      1045\n",
      "           1       0.28      0.13      0.18       352\n",
      "           2       0.40      0.39      0.40      1246\n",
      "           3       0.56      0.70      0.62       382\n",
      "           4       0.45      0.49      0.47      1989\n",
      "           5       0.33      0.12      0.17       339\n",
      "           6       0.40      0.48      0.43      1236\n",
      "\n",
      "    accuracy                           0.41      6589\n",
      "   macro avg       0.39      0.37      0.37      6589\n",
      "weighted avg       0.40      0.41      0.40      6589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_num, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-somalia",
   "metadata": {},
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "straight-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.645273685455322\n"
     ]
    }
   ],
   "source": [
    "# Times how long it takes to score all documents\n",
    "start = time.time()\n",
    "all_predictions = final_model.predict(padded_docs)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cooperative-insider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65884"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "verified-tragedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2951.7921146953404"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Averages documents scored per second\n",
    "len(all_predictions) / 22.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "identical-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe with all predictions\n",
    "predictions_dataframe = pd.DataFrame(all_predictions, columns = ['Action/Adventure', 'Animation/Family', 'Comedy', \n",
    "                                             'Docuemntary', 'Drama', 'History/War/Western', 'Thriller/Horror'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "missing-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers all predictions\n",
    "predicted_class = np.argmax(all_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "corporate-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames predictions numbers to actual genre namme\n",
    "predictions_dataframe['Prediction'] = predicted_class.tolist()\n",
    "predictions_dataframe['Prediction'] = predictions_dataframe['Prediction'].map({0:'Action/Adventure', \n",
    "                                                                               1: 'Animation/Family', \n",
    "                                                                               2: 'Comedy', \n",
    "                                                                               3: 'Docuemntary', \n",
    "                                                                               4: 'Drama', \n",
    "                                                                               5: 'History/War/Western', \n",
    "                                                                               6: 'Thriller/Horror'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "latin-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concats predictions and original overview dataframe together\n",
    "genre_overview_predictions = pd.concat([genres[['original_title', 'overview', 'genres_group']].reset_index(drop = True), predictions_dataframe], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "waiting-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = genre_overview_predictions[genre_overview_predictions['genres_group'] == genre_overview_predictions['Prediction']]\n",
    "misclassified = genre_overview_predictions[genre_overview_predictions['genres_group'] != genre_overview_predictions['Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "foster-wildlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['original_title'] == 'Toy Story']['overview'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "strategic-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres_group</th>\n",
       "      <th>Action/Adventure</th>\n",
       "      <th>Animation/Family</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Docuemntary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>History/War/Western</th>\n",
       "      <th>Thriller/Horror</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>lead woody andys toy happily room andys birthd...</td>\n",
       "      <td>Animation/Family</td>\n",
       "      <td>0.118108</td>\n",
       "      <td>0.296782</td>\n",
       "      <td>0.431155</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.130151</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>lead woody andys toy happily room andys birthd...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>0.118108</td>\n",
       "      <td>0.296782</td>\n",
       "      <td>0.431155</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.130151</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_title                                           overview  \\\n",
       "0      Toy Story  lead woody andys toy happily room andys birthd...   \n",
       "1      Toy Story  lead woody andys toy happily room andys birthd...   \n",
       "\n",
       "       genres_group  Action/Adventure  Animation/Family    Comedy  \\\n",
       "0  Animation/Family          0.118108          0.296782  0.431155   \n",
       "1            Comedy          0.118108          0.296782  0.431155   \n",
       "\n",
       "   Docuemntary     Drama  History/War/Western  Thriller/Horror Prediction  \n",
       "0     0.003588  0.130151             0.005305         0.014911     Comedy  \n",
       "1     0.003588  0.130151             0.005305         0.014911     Comedy  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Toy Story Predictions\n",
    "genre_overview_predictions[genre_overview_predictions['original_title'] == 'Toy Story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "talented-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres_group</th>\n",
       "      <th>Action/Adventure</th>\n",
       "      <th>Animation/Family</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Docuemntary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>History/War/Western</th>\n",
       "      <th>Thriller/Horror</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JumanjiJumanjiJumanjiJumanjiJumanjiJumanjiJuma...</td>\n",
       "      <td>sibling judy peter discover enchanted board ga...</td>\n",
       "      <td>Action/AdventureAction/AdventureAction/Adventu...</td>\n",
       "      <td>46.399998</td>\n",
       "      <td>11.200001</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.800001</td>\n",
       "      <td>Action/AdventureAction/AdventureAction/Adventu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JumanjiJumanjiJumanjiJumanjiJumanjiJumanjiJuma...</td>\n",
       "      <td>sibling judy peter discover enchanted board ga...</td>\n",
       "      <td>Animation/FamilyAnimation/FamilyAnimation/Fami...</td>\n",
       "      <td>46.399998</td>\n",
       "      <td>11.200001</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.800001</td>\n",
       "      <td>Action/AdventureAction/AdventureAction/Adventu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      original_title  \\\n",
       "2  JumanjiJumanjiJumanjiJumanjiJumanjiJumanjiJuma...   \n",
       "3  JumanjiJumanjiJumanjiJumanjiJumanjiJumanjiJuma...   \n",
       "\n",
       "                                            overview  \\\n",
       "2  sibling judy peter discover enchanted board ga...   \n",
       "3  sibling judy peter discover enchanted board ga...   \n",
       "\n",
       "                                        genres_group  Action/Adventure  \\\n",
       "2  Action/AdventureAction/AdventureAction/Adventu...         46.399998   \n",
       "3  Animation/FamilyAnimation/FamilyAnimation/Fami...         46.399998   \n",
       "\n",
       "   Animation/Family  Comedy  Docuemntary  Drama  History/War/Western  \\\n",
       "2         11.200001    13.2          0.5    7.8                  0.1   \n",
       "3         11.200001    13.2          0.5    7.8                  0.1   \n",
       "\n",
       "   Thriller/Horror                                         Prediction  \n",
       "2        20.800001  Action/AdventureAction/AdventureAction/Adventu...  \n",
       "3        20.800001  Action/AdventureAction/AdventureAction/Adventu...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Jumani Predictions\n",
    "round(genre_overview_predictions[genre_overview_predictions['original_title'] == 'Jumanji'], 3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "conservative-scout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['original_title'] == 'Jumanji']['overview'][3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
